import { OpenAI } from 'openai';
import { aiUsageTracker } from './utils/aiUsage';
import { webhookManager } from './utils/webhook';

// Configura√ß√£o do ChatGPT Agent para TeleMed Consulta
let openai: OpenAI | null = null;

// Configura√ß√£o de modelos e retry
const PRIMARY_MODEL = process.env.OPENAI_MODEL_PRIMARY || 'gpt-4o';
const FALLBACK_MODEL = process.env.OPENAI_MODEL_FALLBACK || 'gpt-4o-mini';
const MAX_RETRIES = parseInt(process.env.OPENAI_BACKOFF_MAX_RETRIES || '5');

// Fun√ß√£o de delay exponencial
const exponentialDelay = (attempt: number): number => {
  return Math.min(1000 * Math.pow(2, attempt), 30000); // Max 30 segundos
};

// Inicializar OpenAI apenas se a API key estiver dispon√≠vel
if (process.env.OPENAI_API_KEY) {
  openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
  });
  console.log('ü§ñ OpenAI Client inicializado com sucesso');
} else {
  console.log('‚ö†Ô∏è OPENAI_API_KEY n√£o encontrada - ChatGPT Agent em modo simula√ß√£o');
}

// Prompt inicial para configurar o agente
const telemedPrompt = `
Voc√™ √© meu assistente de desenvolvimento para o sistema TeleMed Consulta, uma plataforma de telemedicina brasileira.

CONTEXTO DO SISTEMA:
- Plataforma completa de telemedicina com Dashboard Aquarela
- Frontend: React.js com TypeScript, Tailwind CSS, shadcn/ui
- Backend: Node.js, Express.js, PostgreSQL com Drizzle ORM  
- Autentica√ß√£o: Replit Auth + JWT com Base64 encryption
- Funcionalidades: Videoconsultas, triagem psiqui√°trica, prescri√ß√µes digitais MEMED, sistema de leil√£o de consultas, notifica√ß√µes SMS/WhatsApp

CARACTER√çSTICAS T√âCNICAS:
- Design aquarela com cores suaves (#F5E8C7, #E0D7B9, #B3D9E0)
- Mobile-first, responsivo para todos os dispositivos
- Integra√ß√£o PostgreSQL com dados reais de m√©dicos e pacientes
- Sistema de notifica√ß√µes m√©dicas via Twilio/WhatsApp
- Testes psiqui√°tricos: GAD-7, PHQ-9, MDQ, PSS-10
- PDF generation com jsPDF e HTML2Canvas
- WebRTC para videoconsultas seguras

COMPLIANCE E SEGURAN√áA:
- LGPD e HIPAA compliance obrigat√≥rio
- Criptografia de dados sens√≠veis
- Logs de auditoria m√©dica
- IP tracking e rate limiting
- Session management seguro

DIRETRIZES DE DESENVOLVIMENTO:
- C√≥digo TypeScript otimizado e type-safe
- Componentes reutiliz√°veis com shadcn/ui
- Performance e acessibilidade (WCAG 2.1)
- Testes automatizados com Vitest
- Documenta√ß√£o completa em Markdown
- Git workflow com commits estruturados

DESIGN SYSTEM:
- Cores m√©dicas profissionais com tons aquarela
- Anima√ß√µes suaves e microintera√ß√µes
- Cards com glass morphism e hover effects
- Tipografia Inter para legibilidade m√©dica
- Icons lucide-react para consist√™ncia

Sua tarefa √© fornecer c√≥digo otimizado, seguir boas pr√°ticas de seguran√ßa e performance, al√©m de gerar documentos e testes automatizados espec√≠ficos para ambiente m√©dico brasileiro.
`;

// Wrapper de resili√™ncia para chamadas OpenAI
async function callOpenAIWithResilience(
  messages: any[],
  model: string = PRIMARY_MODEL,
  attempt: number = 0,
  useFallback: boolean = false
): Promise<string> {
  const currentModel = useFallback ? FALLBACK_MODEL : model;
  
  try {
    // Track da tentativa
    await aiUsageTracker.trackRequest(currentModel);
    
    console.log(`ü§ñ OpenAI Request: ${currentModel} (attempt ${attempt + 1}/${MAX_RETRIES + 1})`);
    
    if (!openai) {
      throw new Error('OpenAI client n√£o inicializado');
    }
    
    const completion = await openai.chat.completions.create({
      model: currentModel,
      messages,
      max_tokens: 2000,
      temperature: 0.7,
    });

    const content = completion.choices[0]?.message?.content;
    if (!content) {
      throw new Error('Resposta vazia da OpenAI');
    }

    // Track sucesso
    await aiUsageTracker.trackSuccess();
    
    // Se usou fallback, alerta
    if (useFallback) {
      await aiUsageTracker.trackFallback();
      await webhookManager.alertFallbackActivated({
        model: currentModel,
        attempt,
        originalModel: model
      });
    }

    console.log(`‚úÖ OpenAI Success: ${currentModel} (${content.length} chars)`);
    return content;

  } catch (error: any) {
    console.error(`‚ùå OpenAI Error (${currentModel}, attempt ${attempt + 1}):`, {
      status: error?.response?.status || error?.status,
      code: error?.code,
      type: error?.type,
      message: error?.message
    });

    // Track erro
    await aiUsageTracker.trackError(error?.code || 'unknown', error?.message);

    // Classificar erro e decidir estrat√©gia
    const errorCode = error?.code;
    const statusCode = error?.response?.status || error?.status;

    // Erros cr√≠ticos que n√£o devem fazer retry
    if (errorCode === 'insufficient_quota') {
      await webhookManager.alertQuotaExceeded({ error: error?.message, model: currentModel });
      throw error;
    }
    
    if (errorCode === 'billing_hard_limit_reached') {
      await webhookManager.alertBillingLimit({ error: error?.message, model: currentModel });
      throw error;
    }

    if (statusCode === 401) {
      await webhookManager.alertAPIError({ error: 'Invalid API Key', model: currentModel });
      throw error;
    }

    // Rate limits e erros tempor√°rios - tentar fallback ou retry
    if (errorCode === 'rate_limit_exceeded' || statusCode === 429) {
      await webhookManager.alertRateLimit({ error: error?.message, model: currentModel, attempt });
    }

    // Tentar fallback se n√£o est√° usando ainda
    if (!useFallback && (errorCode === 'rate_limit_exceeded' || statusCode === 429 || statusCode >= 500)) {
      console.log(`üîÑ Tentando modelo fallback: ${FALLBACK_MODEL}`);
      return callOpenAIWithResilience(messages, model, attempt, true);
    }

    // Retry com backoff se ainda h√° tentativas
    if (attempt < MAX_RETRIES) {
      await aiUsageTracker.trackRetry();
      const delay = exponentialDelay(attempt);
      console.log(`‚è≥ Retry em ${delay}ms (attempt ${attempt + 1}/${MAX_RETRIES})`);
      
      await new Promise(resolve => setTimeout(resolve, delay));
      return callOpenAIWithResilience(messages, model, attempt + 1, useFallback);
    }

    // Esgotou tentativas
    console.error(`üí• Todas as tentativas falharam para ${currentModel}`);
    throw error;
  }
}

export class TelemedChatGPTAgent {
  private initialized = false;

  async inicializar(): Promise<string> {
    if (!openai) {
      const simulatedResponse = JSON.stringify({
        agent: "telemed-chatgpt",
        mode: "simulation",
        message: 'Ol√°! Sou o assistente de desenvolvimento do TeleMed Consulta. Estou configurado e pronto para ajudar com desenvolvimento m√©dico, mas estou rodando em modo simula√ß√£o porque a chave da OpenAI API n√£o est√° dispon√≠vel. Para ativa√ß√£o completa, configure a OPENAI_API_KEY.',
        timestamp: new Date().toISOString()
      });
      console.log('üîÑ ChatGPT Agent em modo simula√ß√£o');
      return simulatedResponse;
    }

    try {
      const response = await openai.chat.completions.create({
        model: 'gpt-3.5-turbo', // Modelo compat√≠vel com a maioria das API keys
        messages: [
          { 
            role: 'system', 
            content: telemedPrompt 
          },
          { 
            role: 'user', 
            content: 'Inicialize como assistente de desenvolvimento do TeleMed Consulta. Confirme que entendeu o contexto e est√° pronto para ajudar.' 
          }
        ],
        temperature: 0.7,
        max_tokens: 1000
      });

      this.initialized = true;
      const agentResponse = response.choices[0].message.content || '';
      
      const formattedResponse = JSON.stringify({
        agent: "telemed-chatgpt",
        mode: "production",
        message: agentResponse,
        timestamp: new Date().toISOString()
      });
      
      console.log('ü§ñ ChatGPT Agent inicializado para TeleMed Consulta');
      console.log('üìã Resposta do Agent:', agentResponse);
      
      return formattedResponse;
    } catch (error: any) {
      console.error("OPENAI_ERROR - INITIALIZATION", {
        status: error?.response?.status || error?.status,
        data: error?.response?.data || error?.error,
        code: error?.code,
        type: error?.type,
        message: error?.message
      });

      // Log espec√≠fico para diferentes tipos de erro OpenAI
      if (error?.code === 'insufficient_quota') {
        console.error('üö´ QUOTA EXCEDIDA: Limite de uso da OpenAI atingido');
      } else if (error?.code === 'billing_hard_limit_reached') {
        console.error('üí≥ LIMITE DE BILLING: Limite de cobran√ßa atingido');
      } else if (error?.code === 'rate_limit_exceeded') {
        console.error('‚è±Ô∏è RATE LIMIT: Muitas requisi√ß√µes simult√¢neas');
      } else if (error?.status === 401) {
        console.error('üîë API KEY INV√ÅLIDA: Verifique OPENAI_API_KEY');
      }

      throw new Error('Falha na inicializa√ß√£o do ChatGPT Agent');
    }
  }

  async perguntarAgent(pergunta: string): Promise<string> {
    if (!this.initialized) {
      await this.inicializar();
    }

    if (!openai) {
      return JSON.stringify({
        agent: "telemed-chatgpt",
        mode: "simulation",
        question: pergunta,
        message: `[MODO SIMULA√á√ÉO] Recebi sua pergunta: "${pergunta}". O ChatGPT Agent est√° configurado corretamente mas necessita da chave OPENAI_API_KEY para funcionar completamente. Todas as rotas e integra√ß√µes est√£o funcionais.`,
        timestamp: new Date().toISOString()
      });
    }

    try {
      const messages = [
        { role: 'system', content: telemedPrompt },
        { role: 'user', content: pergunta }
      ];

      const content = await callOpenAIWithResilience(messages, PRIMARY_MODEL);
      return JSON.stringify({
        agent: "telemed-chatgpt",
        mode: "production", 
        question: pergunta,
        message: content,
        timestamp: new Date().toISOString()
      });
    } catch (error: any) {
      console.error("OPENAI_ERROR - QUERY", {
        status: error?.response?.status || error?.status,
        data: error?.response?.data || error?.error,
        code: error?.code,
        type: error?.type,
        message: error?.message,
        question: pergunta
      });

      // Log espec√≠fico para diferentes tipos de erro OpenAI
      if (error?.code === 'insufficient_quota') {
        console.error('üö´ QUOTA EXCEDIDA: Limite de uso da OpenAI atingido');
      } else if (error?.code === 'billing_hard_limit_reached') {
        console.error('üí≥ LIMITE DE BILLING: Limite de cobran√ßa atingido');
      } else if (error?.code === 'rate_limit_exceeded') {
        console.error('‚è±Ô∏è RATE LIMIT: Muitas requisi√ß√µes simult√¢neas');
      } else if (error?.status === 401) {
        console.error('üîë API KEY INV√ÅLIDA: Verifique OPENAI_API_KEY');
      } else if (error?.status === 429) {
        console.error('‚ö†Ô∏è RATE LIMIT 429: Limite de requisi√ß√µes por minuto excedido');
      }

      throw new Error('Falha na comunica√ß√£o com ChatGPT Agent');
    }
  }

  async gerarCodigo(especificacao: string): Promise<string> {
    const prompt = `
    Como assistente de desenvolvimento do TeleMed Consulta, gere c√≥digo TypeScript/React para:
    
    ${especificacao}
    
    Considera√ß√µes obrigat√≥rias:
    - Use componentes shadcn/ui quando poss√≠vel
    - Aplique design system aquarela do TeleMed
    - Implemente responsividade mobile-first
    - Adicione tratamento de erro adequado
    - Inclua tipos TypeScript completos
    - Siga padr√µes de acessibilidade m√©dica
    - Considere LGPD/HIPAA compliance
    `;

    return await this.perguntarAgent(prompt);
  }

  async otimizarCodigo(codigoAtual: string, objetivo: string): Promise<string> {
    const prompt = `
    Otimize o seguinte c√≥digo do TeleMed Consulta:
    
    C√ìDIGO ATUAL:
    ${codigoAtual}
    
    OBJETIVO:
    ${objetivo}
    
    Forne√ßa vers√£o otimizada com explica√ß√£o das melhorias aplicadas.
    `;

    return await this.perguntarAgent(prompt);
  }
}

// Export da inst√¢ncia singleton
export const telemedAgent = new TelemedChatGPTAgent();

// Export do m√©todo perguntarAgent para uso direto
export const perguntarAgent = async (pergunta: string): Promise<string> => {
  return await telemedAgent.perguntarAgent(pergunta);
};

// Export do wrapper de resili√™ncia para uso avan√ßado
export { callOpenAIWithResilience };

// Fun√ß√£o de inicializa√ß√£o r√°pida
export async function inicializarTelemedAgent(): Promise<void> {
  try {
    await telemedAgent.inicializar();
    console.log('‚úÖ TeleMed ChatGPT Agent pronto para uso');
  } catch (error) {
    console.error('‚ùå Falha na inicializa√ß√£o do TeleMed Agent:', error);
  }
}